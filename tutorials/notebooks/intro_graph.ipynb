{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFlowNet Ring Graph Generation Tutorial\n",
    "\n",
    "This tutorial demonstrates how to train a GFlowNet to generate ring graphs - where each vertex has exactly two neighbors and the edges form a single cycle containing all vertices. We'll explore both directed and undirected ring generation.\n",
    "\n",
    "## Introduction to GFlowNets\n",
    "\n",
    "GFlowNets (Generative Flow Networks) are a class of generative models designed for sequential decision-making problems. They learn to sample compositional objects by constructing them step by step. In this tutorial, we'll apply GFlowNets to the task of generating ring graphs.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's first import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oyounis-iit.local/anaconda3/envs/torchgfn/lib/python3.11/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from matplotlib import patches\n",
    "\n",
    "from gfn.containers import ReplayBuffer\n",
    "from gfn.gflownet.trajectory_balance import TBGFlowNet\n",
    "from gfn.gym.graph_building import GraphBuildingOnEdges\n",
    "from gfn.modules import DiscreteGraphPolicyEstimator\n",
    "from gfn.states import GraphStates\n",
    "from gfn.utils.modules import GraphEdgeActionGNN, GraphEdgeActionMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Reward Function\n",
    "\n",
    "A crucial component of GFlowNet training is the reward function that evaluates whether a generated graph forms a valid ring structure. We define different validation logic for directed and undirected rings:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class RingReward(object):\n",
    "    \"\"\"\n",
    "    This function evaluates if a graph forms a valid ring (directed or\n",
    "        undirected cycle).\n",
    "\n",
    "    Args:\n",
    "        directed: Whether the graph is directed.\n",
    "        reward_val: The reward for valid directed rings.\n",
    "        eps_val: The reward for invalid structures.\n",
    "\n",
    "    Returns:\n",
    "        A tensor of rewards with the same batch shape as states\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        directed: bool,\n",
    "        reward_val: float = 100.0,\n",
    "        eps_val: float = 1e-6,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "    ):\n",
    "        self.directed = directed\n",
    "        self.reward_val = reward_val\n",
    "        self.eps_val = eps_val\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, states: GraphStates) -> torch.Tensor:\n",
    "        if self.directed:\n",
    "            return self.directed_reward(states)\n",
    "        else:\n",
    "            return self.undirected_reward(states)\n",
    "\n",
    "    def directed_reward(self, states: GraphStates) -> torch.Tensor:\n",
    "        \"\"\"Compute reward for directed ring graphs.\n",
    "\n",
    "        This function evaluates if a graph forms a valid directed ring (cycle).\n",
    "        A valid directed ring must satisfy these conditions:\n",
    "        1. Each node must have exactly one outgoing edge (row sum = 1 in\n",
    "            adjacency matrix).\n",
    "        2. Each node must have exactly one incoming edge (column sum = 1 in\n",
    "            adjacency matrix).\n",
    "        3. Following the edges must form a single cycle that includes all nodes.\n",
    "\n",
    "        Args:\n",
    "            states: A batch of graph states to evaluate.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of rewards with the same batch shape as states.\n",
    "        \"\"\"\n",
    "        if states.tensor.edge_index.numel() == 0:\n",
    "            return torch.full(states.batch_shape, self.eps_val, device=self.device)\n",
    "\n",
    "        out = torch.full(\n",
    "            (len(states),), self.eps_val, device=self.device\n",
    "        )  # Default reward.\n",
    "\n",
    "        for i in range(len(states)):\n",
    "            graph = states[i]\n",
    "            adj_matrix = torch.zeros(graph.tensor.num_nodes, graph.tensor.num_nodes)\n",
    "            adj_matrix[graph.tensor.edge_index[0], graph.tensor.edge_index[1]] = 1\n",
    "\n",
    "            # Check if each node has exactly one outgoing edge (row sum = 1)\n",
    "            if not torch.all(adj_matrix.sum(dim=1) == 1):\n",
    "                continue\n",
    "\n",
    "            # Check that each node has exactly one incoming edge (column sum = 1)\n",
    "            if not torch.all(adj_matrix.sum(dim=0) == 1):\n",
    "                continue\n",
    "\n",
    "            # Starting from node 0, follow edges and see if we visit all nodes\n",
    "            # and return to the start\n",
    "            visited, current = [], 0  # Start from node 0.\n",
    "\n",
    "            while current not in visited:\n",
    "                visited.append(current)\n",
    "\n",
    "                # Get the outgoing neighbor\n",
    "                current = torch.where(adj_matrix[int(current)] == 1)[0].item()\n",
    "\n",
    "                # If we've visited all nodes and returned to 0, it's a valid ring\n",
    "                if len(visited) == graph.tensor.num_nodes and current == 0:\n",
    "                    out[i] = self.reward_val\n",
    "                    break\n",
    "\n",
    "        return out.view(*states.batch_shape)\n",
    "\n",
    "    def undirected_reward(self, states: GraphStates) -> torch.Tensor:\n",
    "        \"\"\"Compute reward for undirected ring graphs.\n",
    "\n",
    "        This function evaluates if a graph forms a valid undirected ring (cycle).\n",
    "        A valid undirected ring must satisfy these conditions:\n",
    "        1. Each node must have exactly two neighbors (degree = 2)\n",
    "        2. The graph must form a single connected cycle including all nodes.\n",
    "\n",
    "        The algorithm:\n",
    "        1. Checks that all nodes have degree 2\n",
    "        2. Performs a traversal starting from node 0, following edges\n",
    "        3. Checks if the traversal visits all nodes and returns to start\n",
    "\n",
    "        Args:\n",
    "            states: A batch of graph states to evaluate\n",
    "\n",
    "        Returns:\n",
    "            A tensor of rewards with the same batch shape as states\n",
    "        \"\"\"\n",
    "        if states.tensor.edge_index.numel() == 0:\n",
    "            return torch.full(states.batch_shape, self.eps_val, device=self.device)\n",
    "\n",
    "        out = torch.full(\n",
    "            (len(states),), self.eps_val, device=self.device\n",
    "        )  # Default reward.\n",
    "\n",
    "        for i in range(len(states)):\n",
    "            graph = states[i]\n",
    "            if graph.tensor.num_nodes == 0:\n",
    "                continue\n",
    "            adj_matrix = torch.zeros(graph.tensor.num_nodes, graph.tensor.num_nodes)\n",
    "            adj_matrix[graph.tensor.edge_index[0], graph.tensor.edge_index[1]] = 1\n",
    "            adj_matrix[graph.tensor.edge_index[1], graph.tensor.edge_index[0]] = 1\n",
    "\n",
    "            # In an undirected ring, every vertex should have degree 2.\n",
    "            if not torch.all(adj_matrix.sum(dim=1) == 2):\n",
    "                continue\n",
    "\n",
    "            # Traverse the cycle starting from vertex 0.\n",
    "            start_vertex = 0\n",
    "            visited = [start_vertex]\n",
    "            neighbors = torch.where(adj_matrix[start_vertex] == 1)[0]\n",
    "            if neighbors.numel() == 0:\n",
    "                continue\n",
    "            # Arbitrarily choose one neighbor to begin the traversal.\n",
    "            current = neighbors[0].item()\n",
    "            prev = start_vertex\n",
    "\n",
    "            while True:\n",
    "                if current == start_vertex:\n",
    "                    break\n",
    "                visited.append(int(current))\n",
    "                current_neighbors = torch.where(adj_matrix[int(current)] == 1)[0]\n",
    "                # Exclude the neighbor we just came from.\n",
    "                current_neighbors_list = [n.item() for n in current_neighbors]\n",
    "                possible = [n for n in current_neighbors_list if n != prev]\n",
    "                if len(possible) != 1:\n",
    "                    break\n",
    "                next_node = possible[0]\n",
    "                prev, current = current, next_node\n",
    "\n",
    "            if current == start_vertex and len(visited) == graph.tensor.num_nodes:\n",
    "                out[i] = self.reward_val\n",
    "\n",
    "        return out.view(*states.batch_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Function\n",
    "\n",
    "To understand what the model is generating, we need a visualization function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def render_states(states: GraphStates, state_evaluator: callable, directed: bool):\n",
    "    \"\"\"Visualize a batch of graph states as ring structures.\n",
    "\n",
    "    This function creates a matplotlib visualization of graph states, rendering them\n",
    "    as circular layouts with nodes positioned evenly around a circle. For directed\n",
    "    graphs, edges are shown as arrows; for undirected graphs, edges are shown as lines.\n",
    "\n",
    "    The visualization includes:\n",
    "    - Circular positioning of nodes\n",
    "    - Drawing edges between connected nodes\n",
    "    - Displaying the reward value for each graph\n",
    "\n",
    "    Args:\n",
    "        states: A batch of graphs to visualize\n",
    "        state_evaluator: Function to compute rewards for each graph\n",
    "        directed: Whether to render directed or undirected edges\n",
    "    \"\"\"\n",
    "    rewards = state_evaluator(states)\n",
    "    fig, ax = plt.subplots(2, 4, figsize=(15, 7))\n",
    "    for i in range(8):\n",
    "        current_ax = ax[i // 4, i % 4]\n",
    "        state = states[i]\n",
    "        n_circles = state.tensor.num_nodes\n",
    "        radius = 5\n",
    "        xs, ys = [], []\n",
    "        for j in range(n_circles):\n",
    "            angle = 2 * math.pi * j / n_circles\n",
    "            x = radius * math.cos(angle)\n",
    "            y = radius * math.sin(angle)\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "            current_ax.add_patch(\n",
    "                patches.Circle((x, y), 0.5, facecolor=\"none\", edgecolor=\"black\")\n",
    "            )\n",
    "\n",
    "        edge_index = states[i].tensor.edge_index\n",
    "\n",
    "        for edge in edge_index.T:\n",
    "            start_x, start_y = xs[edge[0]], ys[edge[0]]\n",
    "            end_x, end_y = xs[edge[1]], ys[edge[1]]\n",
    "            dx = end_x - start_x\n",
    "            dy = end_y - start_y\n",
    "            length = math.sqrt(dx**2 + dy**2)\n",
    "            dx, dy = dx / length, dy / length\n",
    "\n",
    "            circle_radius = 0.5\n",
    "            head_thickness = 0.2\n",
    "\n",
    "            start_x += dx * circle_radius\n",
    "            start_y += dy * circle_radius\n",
    "            if directed:\n",
    "                end_x -= dx * circle_radius\n",
    "                end_y -= dy * circle_radius\n",
    "                current_ax.arrow(\n",
    "                    start_x,\n",
    "                    start_y,\n",
    "                    end_x - start_x,\n",
    "                    end_y - start_y,\n",
    "                    head_width=head_thickness,\n",
    "                    head_length=head_thickness,\n",
    "                    fc=\"black\",\n",
    "                    ec=\"black\",\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                end_x -= dx * (circle_radius + head_thickness)\n",
    "                end_y -= dy * (circle_radius + head_thickness)\n",
    "                current_ax.plot([start_x, end_x], [start_y, end_y], color=\"black\")\n",
    "\n",
    "        current_ax.set_title(f\"State {i}, $r={rewards[i]:.2f}$\")\n",
    "        current_ax.set_xlim(-(radius + 1), radius + 1)\n",
    "        current_ax.set_ylim(-(radius + 1), radius + 1)\n",
    "        current_ax.set_aspect(\"equal\")\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "\n",
    "Now we'll define the main training function that will put everything together:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ring_gflownet(\n",
    "    n_nodes=4,\n",
    "    n_iterations=200,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    directed=True,\n",
    "    use_buffer=False,\n",
    "    use_gnn=True,\n",
    "    num_conv_layers=1,\n",
    "    device=\"cpu\",\n",
    "    plot=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a GFlowNet to generate ring graphs.\n",
    "\n",
    "    Args:\n",
    "        n_nodes: Number of nodes in the graph\n",
    "        n_iterations: Number of training iterations\n",
    "        lr: Learning rate for optimizer\n",
    "        batch_size: Batch size for training\n",
    "        directed: Whether to generate directed rings\n",
    "        use_buffer: Whether to use a replay buffer\n",
    "        use_gnn: Whether to use GNN-based policy (True) or MLP-based policy (False)\n",
    "        num_conv_layers: Number of convolutional layers (only used if use_gnn=True)\n",
    "        device: Device to run on (\"cpu\" or \"cuda\")\n",
    "        plot: Whether to plot generated graphs after training\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained GFlowNet, environment, state evaluator, training losses)\n",
    "    \"\"\"\n",
    "    device = torch.device(device)\n",
    "\n",
    "    state_evaluator = RingReward(\n",
    "        directed=directed,\n",
    "        reward_val=100.0,\n",
    "        eps_val=1e-6,\n",
    "        device=device,\n",
    "    )\n",
    "    torch.random.manual_seed(7)\n",
    "\n",
    "    env = GraphBuildingOnEdges(\n",
    "        n_nodes=n_nodes,\n",
    "        state_evaluator=state_evaluator,\n",
    "        directed=directed,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Choose model type based on use_gnn flag\n",
    "    if use_gnn:\n",
    "        module_pf = GraphEdgeActionGNN(\n",
    "            env.n_nodes,\n",
    "            directed,\n",
    "            num_conv_layers=num_conv_layers,\n",
    "            num_edge_classes=env.num_edge_classes,\n",
    "        )\n",
    "        module_pb = GraphEdgeActionGNN(\n",
    "            env.n_nodes,\n",
    "            directed,\n",
    "            is_backward=True,\n",
    "            num_conv_layers=num_conv_layers,\n",
    "            num_edge_classes=env.num_edge_classes,\n",
    "        )\n",
    "    else:\n",
    "        module_pf = GraphEdgeActionMLP(\n",
    "            env.n_nodes,\n",
    "            directed,\n",
    "            num_edge_classes=env.num_edge_classes,\n",
    "        )\n",
    "        module_pb = GraphEdgeActionMLP(\n",
    "            env.n_nodes,\n",
    "            directed,\n",
    "            is_backward=True,\n",
    "            num_edge_classes=env.num_edge_classes,\n",
    "        )\n",
    "\n",
    "    pf = DiscreteGraphPolicyEstimator(\n",
    "        module=module_pf,\n",
    "    )\n",
    "    pb = DiscreteGraphPolicyEstimator(\n",
    "        module=module_pb,\n",
    "        is_backward=True,\n",
    "    )\n",
    "    gflownet = TBGFlowNet(pf, pb).to(device)\n",
    "    optimizer = torch.optim.Adam(gflownet.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(\n",
    "        env,\n",
    "        capacity=batch_size,\n",
    "        prioritized=True,\n",
    "    )\n",
    "\n",
    "    losses = []\n",
    "    ring_percentages = []\n",
    "\n",
    "    print(f\"Starting training on {device} device...\")\n",
    "    print(f\"Training parameters: n_nodes={n_nodes}, directed={directed}, use_gnn={use_gnn}\")\n",
    "    \n",
    "    t1 = time.time()\n",
    "    epsilon_dict = defaultdict(float)\n",
    "    for iteration in range(n_iterations):\n",
    "        epsilon_dict[\"action_type\"] = 0.0  # 0.2 * (1 - iteration / n_iterations)\n",
    "\n",
    "        trajectories = gflownet.sample_trajectories(\n",
    "            env,\n",
    "            n=batch_size,\n",
    "            save_logprobs=True,\n",
    "            epsilon=epsilon_dict,\n",
    "        )\n",
    "        training_samples = gflownet.to_training_samples(trajectories)\n",
    "\n",
    "        # Collect rewards for reporting.\n",
    "        terminating_states = training_samples.terminating_states\n",
    "        assert isinstance(terminating_states, GraphStates)\n",
    "        rewards = state_evaluator(terminating_states)\n",
    "\n",
    "        if use_buffer:\n",
    "            with torch.no_grad():\n",
    "                replay_buffer.add(training_samples)\n",
    "                if iteration > 20:\n",
    "                    training_samples = training_samples[:batch_size // 2]\n",
    "                    buffer_samples = replay_buffer.sample(\n",
    "                        n_trajectories=batch_size // 2\n",
    "                    )\n",
    "                    training_samples.extend(buffer_samples)  # type: ignore\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = gflownet.loss(env, training_samples, recalculate_all_logprobs=True)\n",
    "        pct_rings = torch.mean(rewards > 0.1, dtype=torch.float) * 100\n",
    "        ring_percentages.append(pct_rings.item())\n",
    "        \n",
    "        if iteration % 10 == 0:\n",
    "            print(\n",
    "                \"Iteration {} - Loss: {:.02f}, rings: {:.0f}%\".format(\n",
    "                    iteration, loss.item(), pct_rings\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    t2 = time.time()\n",
    "    print(f\"Training completed in {t2 - t1:.2f} seconds\")\n",
    "    print(f\"Final percentage of valid rings: {ring_percentages[-1]:.0f}%\")\n",
    "\n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(losses)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(ring_percentages)\n",
    "    plt.title('Percentage of Valid Rings')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Valid Rings (%)')\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize generated graphs\n",
    "    if plot:\n",
    "        print(\"\\nGenerating sample graphs...\")\n",
    "        samples_to_render = trajectories.terminating_states[:8]\n",
    "        assert isinstance(samples_to_render, GraphStates)\n",
    "        render_states(samples_to_render, state_evaluator, directed)\n",
    "        \n",
    "    return gflownet, env, state_evaluator, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Directed Ring Generator\n",
    "\n",
    "Let's train a GFlowNet to generate directed ring graphs:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Comparing GNN vs MLP Policies\n",
    "\n",
    "Let's compare the performance of GNN-based policies versus MLP-based policies:\n",
    "\n",
    "\n",
    "```python\n",
    "# Train models with different policy networks and compare\n",
    "def compare_policy_networks():\n",
    "    results = {}\n",
    "    \n",
    "    # Train with GNN\n",
    "    _, _, _, losses_gnn = train_ring_gflownet(\n",
    "        n_nodes=5,\n",
    "        n_iterations=100,\n",
    "        use_gnn=True,\n",
    "        plot=False\n",
    "    )\n",
    "    results['GNN'] = losses_gnn\n",
    "    \n",
    "    # Train with MLP\n",
    "    _, _, _, losses_mlp = train_ring_gflownet(\n",
    "        n_nodes=5,\n",
    "        n_iterations=100,\n",
    "        use_gnn=False,\n",
    "        plot=False\n",
    "    )\n",
    "    results['MLP'] = losses_mlp\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(results['GNN'], label='GNN Policy')\n",
    "    plt.plot(results['MLP'], label='MLP Policy')\n",
    "    plt.title('GNN vs MLP Policy Performance')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the comparison\n",
    "policy_comparison = compare_policy_networks()\n",
    "```\n",
    "\n",
    "## Scaling to Larger Graphs\n",
    "\n",
    "Let's explore how our model performs as we increase the number of nodes:\n",
    "\n",
    "\n",
    "```python\n",
    "def node_scaling_experiment():\n",
    "    node_counts = [4, 6, 8]\n",
    "    results = {}\n",
    "    \n",
    "    for n_nodes in node_counts:\n",
    "        print(f\"\\nTraining with {n_nodes} nodes...\")\n",
    "        _, _, _, losses = train_ring_gflownet(\n",
    "            n_nodes=n_nodes,\n",
    "            n_iterations=100,\n",
    "            plot=False\n",
    "        )\n",
    "        results[n_nodes] = losses\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for n_nodes, losses in results.items():\n",
    "        plt.plot(losses, label=f'{n_nodes} nodes')\n",
    "    \n",
    "    plt.title('Training Loss for Different Graph Sizes')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the scaling experiment\n",
    "scaling_results = node_scaling_experiment()\n",
    "```\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've learned how to train a GFlowNet to generate both directed and undirected ring graphs. We've explored different policy network architectures (GNN vs MLP) and investigated how the model scales with graph size.\n",
    "\n",
    "Key takeaways:\n",
    "1. GFlowNets offer a powerful approach for generating structured graphs with specific constraints\n",
    "2. Graph Neural Networks (GNNs) are well-suited for learning graph generation policies\n",
    "3. The model can be trained to generate both directed and undirected rings\n",
    "4. Training performance depends on graph size, with larger graphs requiring more training iterations\n",
    "\n",
    "GFlowNets can be extended to generate many other types of graph structures, such as trees, grids, or more complex molecular structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Train a directed ring generator\n",
    "gflownet_directed, env_directed, evaluator_directed, losses_directed = train_ring_gflownet(\n",
    "    n_nodes=5,\n",
    "    n_iterations=150,\n",
    "    directed=True,\n",
    "    use_gnn=True,\n",
    "    batch_size=64,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an Undirected Ring Generator\n",
    "\n",
    "Now let's train a GFlowNet to generate undirected ring graphs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Train an undirected ring generator\n",
    "gflownet_undirected, env_undirected, evaluator_undirected, losses_undirected = train_ring_gflownet(\n",
    "    n_nodes=5,\n",
    "    n_iterations=150,\n",
    "    directed=False,\n",
    "    use_gnn=True,\n",
    "    batch_size=64,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from Trained Models\n",
    "\n",
    "We can use our trained models to generate additional ring graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(gflownet, env, evaluator, n_samples=8, directed=True):\n",
    "    \"\"\"Generate samples from a trained GFlowNet and visualize them\"\"\"\n",
    "    trajectories = gflownet.sample_trajectories(env, n=n_samples)\n",
    "    terminating_states = trajectories.terminating_states\n",
    "    render_states(terminating_states, evaluator, directed)\n",
    "    return terminating_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from the directed model\n",
    "directed_samples = generate_samples(\n",
    "    gflownet_directed, env_directed, evaluator_directed, n_samples=8, directed=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from the undirected model\n",
    "undirected_samples = generate_samples(\n",
    "    gflownet_undirected, env_undirected, evaluator_undirected, n_samples=8, directed=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
